{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87ae02ad",
   "metadata": {},
   "source": [
    "# Data Science From Scratch Notes\n",
    "\n",
    "## Chapter 7: Hypothesis and Inference\n",
    "\n",
    "## Statistical Hypothesis Testing\n",
    "\n",
    "Null hypothesis and alternative hypothesis.\n",
    "\n",
    "### Example: Flipping a Coin\n",
    "\n",
    "Let's test whether a coin is fair. We'll assume that the coin has some probability *p* of landing and heads, so our null hypothesis is that the coin is fair - $p = 0.5$. We'll test this agains the alternative hypothesis $p \\neq 0.5$.\n",
    "\n",
    "Each coin flip is a Bernoulli trial, which means that X is a Binomial(n,p) random variable, which we can approximate using the normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b6da35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import math\n",
    "\n",
    "def normal_approximation_to_binomial(n: int, p: float) -> Tuple[float, float]:\n",
    "    \"\"\"Returns mu and sigma corresponding to a Binomial(n,p)\"\"\"\n",
    "    mu = n * p\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d5809",
   "metadata": {},
   "source": [
    "We'll use `normal_cdf` to figure out the probability that a random variable's realized value lies within or outside a particular interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea6c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.probability import normal_cdf\n",
    "\n",
    "# The normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "# It's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo: float,\n",
    "                             mu: float = 0,\n",
    "                             sigma: float = 1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is greater than lo\"\"\"\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# It's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo: float,\n",
    "                               hi: float,\n",
    "                               mu: float = 0,\n",
    "                               sigma: float = 1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is between lo and hi\"\"\"\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# It's outside if it's not between\n",
    "def normal_probability_outside(lo: float,\n",
    "                               hi: float,\n",
    "                               mu: float = 0,\n",
    "                               sigma: float = 1) -> float:\n",
    "    \"\"\"The probability that an N(mu, sigma) is not betweeen lo and hi\"\"\"\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedb767",
   "metadata": {},
   "source": [
    "We can also do the reverse - find either the nontail region or the symmetric interval around the mean that accounts for a certain level of likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ca8a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scratch.probability import inverse_normal_cdf\n",
    "\n",
    "def normal_upper_bound(probability: float,\n",
    "                       mu: float = 0,\n",
    "                       sigma: float = 1) -> float:\n",
    "    \"\"\"Returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability: float,\n",
    "                       mu: float = 0,\n",
    "                       sigma: float = 1) -> float:\n",
    "    \"\"\"Returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability: float,\n",
    "                            mu: float = 0,\n",
    "                            sigma: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    Returns the symmetric bounds that \n",
    "    contain the specified probability\n",
    "    \"\"\"\n",
    "    tail_probability = (1 - probability) / 2\n",
    "    \n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "    \n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "    \n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d15119",
   "metadata": {},
   "source": [
    "Let's say we choose to flip the coin $n= 1000$ times. If our hypothesis of fairness is tru, X should be distributed approximately normally with mean 500 and standard deviation 15.8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8aae23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "15.811388300841896\n"
     ]
    }
   ],
   "source": [
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "\n",
    "print(mu_0)\n",
    "print(sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4c793",
   "metadata": {},
   "source": [
    "Next, we need to make a decision about significance - how willing we are to make a type I error (\"false positive\"), in which we reject $H_0$ even though it's true. Let's choose 5%. Consider the test that rejects $H_0$ if X falls outside the bounds given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c92f69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469.01026640487555\n",
      "530.9897335951244\n"
     ]
    }
   ],
   "source": [
    "# (469, 531)\n",
    "lower_bound, upper_bound = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "print(lower_bound)\n",
    "print(upper_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6c6bee",
   "metadata": {},
   "source": [
    "Assuming *p* really equals 0.5 (i.e., $H_0$ is true), there is just a 5% chance we observe an X that lies outside this interval.\n",
    "\n",
    "We can calculate the power of the test (1 - type 2 error (\"false negative\")):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e63235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469.01026640487555\n",
      "530.9897335951244\n",
      "550.0\n",
      "15.732132722552274\n",
      "0.8865480012953671\n"
     ]
    }
   ],
   "source": [
    "# 95% bounds based on assumption p is 0.5\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "print(lo)\n",
    "print(hi)\n",
    "\n",
    "# actual mu and sigma based on p = 0.55\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "print(mu_1)\n",
    "print(sigma_1)\n",
    "\n",
    "# a type 2 error means we fail to reject the null hypothesis,\n",
    "# which will happen when X is still in our originial interval\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36987d",
   "metadata": {},
   "source": [
    "What if our null hypothesis was that the coin is not biased toward heads, or that $p \\leq 0.5$. In this case, we want a *one-sided test* that rejects the null hypothesis when X is much larger than 500 but not when X is smaller than 500.\n",
    "\n",
    "A 5% significance test involves using `normal_probability_below` to find the cutoff below which 95% probability lies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5004bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9363794803307173\n"
     ]
    }
   ],
   "source": [
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "# is 526 (< 531, since we need more probability in the upper tail)\n",
    "\n",
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print(power)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda5329f",
   "metadata": {},
   "source": [
    "## p-Values\n",
    "\n",
    "Instead of choosing bounds based on some probability cutoff, we compute the probability - assuming $H_0$ is true - that we would see a value at least as extreme as the one we actually observed.\n",
    "\n",
    "For a two-sided test of whether the coin is fair, we compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad2bcec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sided_p_value(x: float, mu: float = 0, sigma: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    How likely are we to see a value at least as extreme as x (in either\n",
    "    direction) if our vaues are from an N(mu, sigma)?\n",
    "    \"\"\"\n",
    "    if x >= mu:\n",
    "        # x is greater than the mean, so the tail is everything greater than x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # x is less than the mean, so the tail is everything less than x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d95ee33",
   "metadata": {},
   "source": [
    "If we were to see 530 heads, we would compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af28c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598835"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(529.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc633fc",
   "metadata": {},
   "source": [
    "We used a value of 529.5 rather than 530 as a continuity correction.\n",
    "\n",
    "We can convince ourselves that this is a sensivle estimate with a simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0778283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "extreme_value_count = 0\n",
    "for _ in range(1000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0 # Count # of heads\n",
    "                    for _ in range(1000)) # in 1000 flips,\n",
    "    if num_heads >= 530 or num_heads <= 470: # and count how often\n",
    "        extreme_value_count += 1 # the # is 'extreme'\n",
    "        \n",
    "# p-value was 0.062 => ~62 extreme values out of 1000\n",
    "assert 59 < extreme_value_count < 65, f\"{extreme_value_count}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914801a4",
   "metadata": {},
   "source": [
    "Since the p-value is greater than our 5% significance, we don't reject the null. If we saw 532 heads, the p-value would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7da8c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046345287837786575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(531.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b293f4",
   "metadata": {},
   "source": [
    "which is smaller than the 5% significance, which means we would reject the null. It's the same test as before, just a different way of approaching statistics.\n",
    "\n",
    "Similarly, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a0ac683",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08688f4",
   "metadata": {},
   "source": [
    "For our one-sided test, if we saw 525 heads we would compute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2793da55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06062885772582072"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(524.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f8f261",
   "metadata": {},
   "source": [
    "which means we wouldn't reject the null. If we saw 527 heads, the computation would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d2e571b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(526.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee17840a",
   "metadata": {},
   "source": [
    "and we would reject the null."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e7984e",
   "metadata": {},
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "A third approach to testing hypotheses is confidence intervals.\n",
    "\n",
    "Since we don't know the exact value of *p*, we use our estimate if we observe 525 heads out of 1,000 flips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc9bbf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * (1 - p_hat) / 1000)\n",
    "\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bec07",
   "metadata": {},
   "source": [
    "Interpretation: 95% of the time, the \"true\" value of *p* will lie between 0.49 and 0.56."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cc1831",
   "metadata": {},
   "source": [
    "## p-Hacking\n",
    "\n",
    "A procedure that erroneously rejects the null hypothesis only 5% of the time will, by definition, 5% of the time erroneously reject the null hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59014dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def run_experiment() -> List[bool]:\n",
    "    \"\"\"Flips a fair coin 1000 times, True = heads, False = tails\"\"\"\n",
    "    return[random.random() < 0.5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment: List[bool]):\n",
    "    \"\"\"using the 5% signicance level\"\"\"\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment\n",
    "                      for experiment in experiments\n",
    "                      if reject_fairness(experiment)])\n",
    "\n",
    "assert num_rejections == 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefa6fab",
   "metadata": {},
   "source": [
    "The implications: Test enough hypotheses against your dataset, and one of them will almost certainly appear significant. Remove the right outliers, and you can probably get your p-value below 0.05.\n",
    "\n",
    "To do good *science*, determine the hypothesis before looking at the data, clean the data without the hypotheses in mind.\n",
    "\n",
    "\n",
    "## Bayesian Inference\n",
    "\n",
    "In the procedures we've looked at, we have made probability statements about our *tests*.\n",
    "\n",
    "An alternative approach involves treating the unknown parameters themselves as random variables. We start with a *prior distribution* for the parameters and then use the observed data and Bayes' theorem to get an updated *posterior distribution* for the parameters. In this approach, we make probability judgements about the parameters rather than the tests.\n",
    "\n",
    "When the unknown parameter is a probability (e.g. coin-flipping), we often use a prior from teh *Beta distribution*, which puts all its probability between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53bf9b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def B(alpha: float, beta: float) -> float:\n",
    "    \"\"\"A normalizing constant so that the total probability is 1\"\"\"\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x: float, alpha: float, beta: float) -> float:\n",
    "    if x <= 0 or x >= 1: # no weight outside of [0, 1]\n",
    "        return 0\n",
    "    return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd41f29",
   "metadata": {},
   "source": [
    "Generally, this distribution centers its weight at $$\\frac{\\alpha}{\\alpha + \\beta}$$ and the larger alpha and beta are, the \"tighter\" the distribution is."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
